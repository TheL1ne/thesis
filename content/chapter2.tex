\chapter{State of the Art}
\section{Entwicklung von Industriellen Netzwerken}
In der Vergangenheit wurden Netzwerke von Fertigungsanlagen speziell für diese eine Anlage entworfen und die Systeme entsprechend von Ingenieuren großteils manuell konfiguriert [Zitat]. Doch Unterhaltungselektronik ist inzwischen so gereift und weit verbreitet, dass es sehr attraktiv ist diese Hardware und Netzwerktechnologien auch für den professionellen Gebrauch zu adaptieren. Dabei haben sich über die letzte Dekade unterschiedliche Teams dieser Aufgabe gewidmet und je nach Schwerpunkt entsprechende Erweiterungen entworfen. So gibt es bereits im Bereich des „real time Ethernet“, dass günstige „fast Ethernet“-Technolgien für den industriellen Einsatz erweitert, drei hauptsächliche Klassen von Technolgien die sich hauptsächlich in der Umsetzung von Echtzeitanforderungen unterscheiden [Zitat].\\
Da es sich viele Industrien nicht leisten können frühzeitig auf eventuell unausgereifte Technologien zu setzen und außerdem Planung, Realisierung und Wartung während des Betreiben von Anlagen viele Jahre bis Jahrzehnte in Anspruch nimmt, werden neue Technologien nur langsam adaptiert [Zitat]. Dem gegenüber stehen schnelle Entwicklungen in der Unterhaltungselektronik, die zu einer großen Nutzerbasis und damit ausführlichen Zuverlässigkeitstests der neuen Technologie geführt haben. So gehört für viele Menschen bereits seit 2006 bzw. den darauf folgenden Jahren ein Smartphone zum Alltag [Zitat]. Mobiles Internet hat diese starke Verbreitung begleitet und war die ursprüngliche Motivation für Echtzeit-Netzwerktechnologien, da Audio- und Videostreaming zu einem starken Wirtschaftsfaktor geworden ist [Zitat Wachstum Streaming]. Aktuell steht im Zuge der weiteren Verbesserung der Bandbreite mobiler Verbindungen die Standardisierung der nächsten Generation in den Startlöchern: das sogenannte „5G“, die fünfte Generation des mobilen Internets.\\
Durch die weitere Verbreitung und intensiven Nutzung durch Milliarden Nutzer haben sich die Technologien und Algorithmen als Fehlerarm erwiesen und damit auch die Aufmerksamkeit der Fertigungsindustrie auf sich gezogen. Deswegen sieht die aktuelle Entwicklung der Industrie vor diese neuen mobilen Endgeräte als Endpunkte für die Darstellung von internen Daten zu nutzen. In Kombination mit den dabei steigenden Endpunkten und kabellosen Geräten, werden auch immer mehr kabellose Sensoren und komplexere Subgeräte eingebaut. Dies geschieht aufgrund der Notwendigkeit die Kosten der Herstellung von immer komplexeren Bauteilen mit einer breiteren Nutzbarkeit entgegen zu wirken. So entstand ein neues Forschungsfeld: „Cyber-physical-Systems“. Dieses Forschungsfeld führt unterschiedlichste Technologien zusammen und ist ein Kernelement der „vierten industriellen Revolution“. Nachdem die dritte durch die Einsatzfähigkeit von kabellosen Verbindungen im industriellen Kontext ausgelöst wurde [Zitat], da Maschinen plötzlich nicht mehr absolut stationär sein mussten oder Sensoren auch an unzugänglichen Stellen verbaut werden konnten.\\
Die vierte industrielle Revolution oder „Industrie 4.0“ [Zitat] wie es auch in vielen Veröffentlichungen genannt wird, konzentriert sich nun auf die massive Ausweitung der Kommunikation zwischen Maschine und Maschine (M2M) und Produkt und Maschine [Zitate]. Die Zukunftsvision sieht dabei vor, dass die Produkte ihren Zustand und die Schritte die noch notwendig sind um sie nach Kundenwunsch fertig zu stellen, kennen. Die notwendigen Ressourcen (wie z.B. Maschinen und Rohstoffe) werden dann bei einem Managementsystem angefordert. Dieses Managementsystem spielt dabei eine so große Rolle, dass es als kritische Komponente permanent verfügbar sein muss und deswegen mit passenden Vorgaben (wie „graceful shutdowns“ und „rolling updates“) in virtuellen Systemen von Cloud-Anbietern ausgerollt wird  um die Kosten der eigenen Infrastruktur zu reduzieren oder zumindest planbarer zu machen [Zitat]. Beide Entwicklungen führen zu einer deutlichen Zunahme der Netzwerkkommunikation in Fertigungsanlagen und setzen ein verlässliches „Wide Area Network“ vorraus.\\
\section{Anomalieerkennung in industriellen Netzwerken}
Doch wie stellt man die Verfügbarkeit und Nutzbarkeit des Netzwerks sicher, wenn es nicht mehr vorgesehen ist alle Teilnehmer manuell zu konfigurieren und zu überwachen? Es ist notwendig Überwachungsaufgaben auf Algorithmen auszulagern. Dafür gibt es aktuell zwei unterschiedliche Ansätze. Auf der einen Seite existiert der „phänomenologische Ansatz“ bei dem Werte des Systems (Sensordaten, Energieverbrauch oder/und Netzwerkdaten) als Anomalie klassifiziert werden. Dies wurde häufig mit Hilfe von Clustering-Algorithmen versucht [Zitat]. Dabei können die zu erwarteten Werte häufig mithilfe von ausgiebiger Simulation bereits vor der Inbetriebnahme eine Fertigungsanlage berechnet werden. Die entsprechenden Simulationen für Motoren, Ventile und Sensoren sind in den letzten Jahren durch viele Anwendungen bestätigt worden [Zitat].\\
Andere Arbeiten haben den Fokus geändert und konzentrieren sich auf die Darstellung des Systems über einen „finite, timed, deterministic Automata“ der sich als ein Set aus einer endlichen Anzahl an Zuständen, Übergängen und Ereignissen darstellen lässt [Zitat]. Dabei wird die Struktur des Automaten in zwei Schritten gewonnen und im dritten folgt dann die Anomalieerkennung [Zitat]. Um folgende Schritte zu vollziehen ist es zwingend Notwendig alle Sensordaten über mehrere Produktionszyklen aufzuzeichnen und in einer Datenbank vorrätig zu halten. Dabei werden die Sensordaten in passende Zeitabschnitte eingeteilt und damit eine diskrete Liste von Ereignissen geschaffen. Die notwendigen Schritte dieses Ansatzes sind:
\begin{enumerate}
\item \textbf{Lernen der Netzwerkstruktur:} Im ersten Schritt muss die grundlegende Struktur des Netzwerks entweder von Konfigurationsdaten abgeleitet (zum Beispiel der Nachbarschaftsinformationen in PROFINET-Systemen) oder manuell konfiguriert werden. Dabei ist zu beachten das hier noch manuelle Arbeit notwendig ist, wenn es nicht aus der Konfiguration abgelesen werden kann. Aber selbst wenn die Möglichkeit des automatischen Auslesens besteht, muss für jede Netzwerktechnolgie ein passendes Programm geschrieben werden um die Informationen zu extrahieren, was bei erstmaliger Nutzung ebenfalls manuelle Arbeit erfordert. Das Resultat dieses Schrittes ist ein Netzwerkmesh, wobei ein Knoten nicht Notwendigerweise einen Teilnehmer des Netzwerks symbolisiert, denn gleiche Knoten werden zu einem verschmolzen.
\item \textbf{Lernen des Verhaltensmodells:}  Basierend auf der zuvor gelernten Netzwerkstruktur und der Ereignisliste für Produktionszyklen, werden Wahrscheinlichkeitsbäume aufgebaut für jeden einzelnen Knoten aufgebaut. Dabei ist zu bemerken, dass Wahrscheinlichkeitsverteilungsfunktionen in Abhängigkeit des relativen Zeitpunkts des Auftreten eines Events genutzt werden um auch mit Unsicherheiten im Modell umgehen zu können.
\item \textbf{Anomalieerkennung:} Hier wird das Modell mit den gemessenen Sensordaten aus der echten Welt simuliert und bei zu großen Abweichungen zwischen Modell und Messungen wird eine Anomalie gemeldet. Dabei gibt es hier noch zwei Ansätze: entweder können Ergebnisse der realen Welt zur Korrektur des Modells aus Schritt 2 genutzt werden oder das Modell bleibt so erhalten wie es ursprünglich mal angelernt wurde.
\end{enumerate}
Mit dieser Art der Anomalieerkennung lassen sich drei Klassen von Fehlern erkennen [Zitat]:
\begin{itemize}
\item \textbf{Funktionale Fehler:} Wenn es keinen Pfad gibt der mit dem Eingangsereignis vom aktuellen Zustand in einen führt. Die Ereignisabfolge, welche hierher geführt hat, ist also nicht vorgesehen.
\item \textbf{Zeitfehler:} ein korrektes Ereignis ist eingegangen, aber es liegt außerhalb des vorgesehenen Zeitfensters für die vorhandenen Übergänge. Das Ereignis war zu früh oder zu spät.
\item \textbf{Wahrscheinlichkeitsfehler:}  Die Wahrscheinlichkeiten mit der Ereignisse im Realsystem auftreten, weicht zu weit von den Wahrscheinlichkeiten im Modell ab.
\end{itemize}
Dieser Ansatz hat ein paar grundlegende Limitierungen, denn wie bereits von den Autoren bei der Evaluierung festgestellt, bedarf es einer Enormen Menge an Messungen im realen System um das gesamte Normalverhalten des Systems abzubilden. Diese Anzahl ist derart hoch, dass es nahezu unmöglich ist diese Anzahl an Lerndaten bereit zu stellen [Zitat]. Dadurch kommt es zu Abweichungen vom Modell, die eine Alarmierung zu Folge haben, obwohl das Realsystem in einem völlig korrekten Rahmen operiert.
\section{Ontologien und Anomalieerkennung}
TODO: Definition Ontologie, Beispiele/Arbeiten für Anomalieerkennung auf Basis von Ontologien